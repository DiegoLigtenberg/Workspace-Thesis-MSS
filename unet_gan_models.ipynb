{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_gan_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfF2KotBIDC7"
      },
      "source": [
        "# preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pVUFgKJMsza"
      },
      "source": [
        "# interactive gpu session\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RHl-lVHKVQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1723bf21-c394-4adc-f8ca-cc1bd4e21dc4"
      },
      "source": [
        "# seed\n",
        "from tensorflow.random import set_seed; \n",
        "from numpy.random import seed;\n",
        "set_seed(0)\n",
        "seed(0)\n",
        "\n",
        "# imports\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.activations import tanh, sigmoid\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model, save_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate, UpSampling2D, Add\n",
        "from tensorflow.keras.layers import LeakyReLU, Dense, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Layer #, Dropout\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.image import sobel_edges\n",
        "from tensorflow import squeeze, concat, stack, Variable\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "# import other notebooks\n",
        "import import_ipynb\n",
        "from data_feeder import DataFeeder\n",
        "from utilities import visualize_training, get_start_time, get_formatted_elapsed_time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from data_feeder.ipynb\n",
            "importing Jupyter notebook from utilities.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgQdPQ1XhZZs"
      },
      "source": [
        "# general (de)convolution block\n",
        "def conv_block(input, nr_filters, kernel_size=3, convolution=True, strides=1, batch_normalization=True, activation=True, use_bias=True):\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  if convolution: out = Conv2D(nr_filters, kernel_size, padding='same', strides=strides, kernel_initializer=init, use_bias=use_bias)(input)\n",
        "  else: out = Conv2DTranspose(nr_filters, kernel_size, padding='same', strides=strides, kernel_initializer=init, use_bias=use_bias)(input)\n",
        "  if batch_normalization: out = BatchNormalization()(out)\n",
        "  if activation: out = LeakyReLU()(out)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmg_UxkT8Am3"
      },
      "source": [
        "# U-Net generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50VdMMLz6d7U"
      },
      "source": [
        "# U-Net generator blocks\n",
        "def decoder_block(input, nr_filters):\n",
        "  # Deconv, BN, LReLU, Conv, BN, LReLU\n",
        "  out = conv_block(input, nr_filters, 4, convolution=False, strides=2)\n",
        "  out = conv_block(out, nr_filters, 3)\n",
        "  return out\n",
        "\n",
        "def multi_scale_block(input, nr_filters):\n",
        "  # Conv, BN, LReLU, Conv, BN, LReLU, Conv\n",
        "  out = conv_block(input, nr_filters, 3)\n",
        "  out = conv_block(out, nr_filters, 3)\n",
        "  out = conv_block(out, nr_filters, 3, batch_normalization=False, activation=False)\n",
        "  return out\n",
        "\n",
        "# U-Net generator class\n",
        "class UNet:\n",
        "  def __init__(self, input, depth=7, nr_filters=64, max_nr_filters=512, nr_add_scales=0):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "     input            input/output shapes (GAN training), DataFeeder object (U-Net training)\n",
        "     depth            number of encoder blocks\n",
        "     nr_filters       number of filters of the first block\n",
        "     max_nr_filters   maximum number of filters\n",
        "     nr_add_scales    number of multi-scale addition blocks\n",
        "\n",
        "    outputs:\n",
        "     UNet model based on input settings\n",
        "    \"\"\"\n",
        "\n",
        "    # use generator as seperate network\n",
        "    if isinstance(input, DataFeeder):\n",
        "      self.data_feeder = input\n",
        "      input_shape = np.load(self.data_feeder.single_energy_dirs[0]).shape\n",
        "      output_shape = np.load(self.data_feeder.dual_energy_dirs[0]).shape\n",
        "\n",
        "    # use as generator in gan\n",
        "    else:\n",
        "      self.data_feeder = None\n",
        "      input_shape = input[0]\n",
        "      output_shape = input[1]\n",
        "    \n",
        "    # number of filters array\n",
        "    self.nr_filters_array = np.minimum(np.ones(depth) * nr_filters * 2 ** np.arange(depth), max_nr_filters).astype(np.int32)\n",
        "    \n",
        "    # reset seeds\n",
        "    set_seed(0)\n",
        "    seed(0)\n",
        "\n",
        "    # input\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    # encoder\n",
        "    encoder, encoder_list = self.encoder_path(input)\n",
        "\n",
        "    # decoder\n",
        "    decoder, decoder_list = self.decoder_path(encoder, encoder_list, output_shape[2])\n",
        "\n",
        "    # mutli-scale output\n",
        "    output = self.multi_scale_path(decoder, decoder_list, output_shape[2], nr_add_scales)\n",
        "\n",
        "    # final model\n",
        "    self.model = Model(inputs=input, outputs=output, name=f\"unet_ms{nr_add_scales}\")\n",
        "\n",
        "    # adam optimizer for both U-Net and GAN training\n",
        "    self.optimizer = Adam(learning_rate=2e-4, beta_1=0.9)\n",
        "\n",
        "    # compile for cnn training\n",
        "    if self.data_feeder != None:\n",
        "      self.model.compile(loss='mae', optimizer=self.optimizer)\n",
        "\n",
        "  def train(self, nr_epochs=100):\n",
        "    # check if model can be trained as U-Net network\n",
        "    if self.data_feeder == None:\n",
        "      print(\"not trainable, initialize with DataFeeder as input to compile and allow training\")\n",
        "    else:\n",
        "      # show training data examples\n",
        "      self.data_feeder.show_data_examples()\n",
        "\n",
        "      # save losses in list\n",
        "      self.loss = []\n",
        "      progress_marker = int(max([self.data_feeder.nr_batches / 30, 1]))\n",
        "\n",
        "      # train\n",
        "      train_start_time = get_start_time()\n",
        "      print(f\"training for {nr_epochs} epochs with {self.data_feeder.nr_batches} batches per epoch\")\n",
        "      for epoch_nr in range(1, nr_epochs + 1):\n",
        "        print(f\"epoch {epoch_nr} \", end=\"\")\n",
        "        batch_start_time = get_start_time()\n",
        "        for batch_nr in range(self.data_feeder.nr_batches):\n",
        "          # get source and target images\n",
        "          se, de_real = self.data_feeder.load_augmented_batch()\n",
        "\n",
        "          # train batch\n",
        "          self.loss.append(self.model.train_on_batch(se, de_real))\n",
        "\n",
        "          # update progress bar based on number of batches\n",
        "          if batch_nr % progress_marker == 0: print(\"=\", end=\"\")\n",
        "\n",
        "        # print results of epoch\n",
        "        print(f\" {self.loss[-1]:.3e} - {get_formatted_elapsed_time(batch_start_time)}\")\n",
        "        \n",
        "        # visualize generator results every few epochs, with more visualization at the end \n",
        "        visualize_training(self.data_feeder, self.model, epoch_nr if epoch_nr != nr_epochs else 0)\n",
        "\n",
        "      # loss\n",
        "      self.loss = np.array(self.loss)\n",
        "      print(f\"total training time: {get_formatted_elapsed_time(train_start_time)}\")\n",
        "\n",
        "  def save(self, save_dir, name_suffix = \"\"):\n",
        "    # save model\n",
        "    model_sir = f\"{save_dir}/{self.model.name}{name_suffix}\"\n",
        "    save_model(self.model, model_sir)\n",
        "\n",
        "    # save loss\n",
        "    np.save(f\"{model_sir}/model_loss.npy\", self.loss)\n",
        "\n",
        "  def plot_loss(self):\n",
        "    # plot training loss\n",
        "    plt.figure()\n",
        "    plt.plot(self.loss)\n",
        "\n",
        "  def encoder_path(self, input):\n",
        "    encoder = input\n",
        "    encoder_list = []\n",
        "    for i, nr_filters in enumerate(self.nr_filters_array):\n",
        "      encoder = conv_block(encoder, nr_filters, 4, strides=2) # encoder block\n",
        "      encoder_list.append(encoder)\n",
        "    return encoder, encoder_list\n",
        "\n",
        "  def decoder_path(self, input, encoder_list, nr_output_channels):\n",
        "    decoder = input\n",
        "    decoder_list = []\n",
        "    for i in range(len(self.nr_filters_array) - 2, -1, -1):\n",
        "      decoder = decoder_block(decoder, self.nr_filters_array[i]) # decoder block\n",
        "      decoder_list.append(decoder)\n",
        "      decoder = Concatenate(axis=3)([encoder_list[i], decoder]) # U-net skip connections\n",
        "    decoder = conv_block(decoder, nr_output_channels, 4, convolution=False, strides=2, batch_normalization=False, activation=False)\n",
        "    return decoder, decoder_list\n",
        "\n",
        "  def multi_scale_path(self, input, decoder_list, nr_output_channels, nr_add_scales):\n",
        "    multi_scale = input\n",
        "    for depth in range(1, nr_add_scales + 1):\n",
        "      scale = 2 ** depth\n",
        "      scaled = multi_scale_block(decoder_list[-depth], nr_output_channels) # mutli-scale block\n",
        "      scaled = UpSampling2D((scale, scale), interpolation=\"bilinear\")(scaled)    \n",
        "      multi_scale = Add()([multi_scale, scaled]) # multiscale elementwise addition\n",
        "    out = Activation(tanh)(multi_scale)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O5Qiz0x8ANE"
      },
      "source": [
        "# PatchGAN discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGBB7yVxRBRJ"
      },
      "source": [
        "class SobelGradient(Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(SobelGradient, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):    \n",
        "    sobel_inputs = sobel_edges(inputs) # get x and y sobel gradients from inputs\n",
        "\n",
        "    # return concatenation of inputs and their x and y sobel gradients\n",
        "    return concat([inputs, sobel_inputs[:,:,:,:,0], sobel_inputs[:,:,:,:,1]], axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6uIZOv57-jo"
      },
      "source": [
        "class Discriminator:\n",
        "  def __init__(self, input_shape, depth=4, nr_filters=64, max_nr_filters=512, sobel_gradient=False):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "     input_shape      input shape\n",
        "     depth            number of encoder blocks\n",
        "     nr_filters       number of filters of the first block\n",
        "     max_nr_filters   maximum number of filters\n",
        "     sobel_gradient   Sobel gradient layer on inputs\n",
        "\n",
        "    outputs:\n",
        "     Discriminator model based on input settings\n",
        "    \"\"\"\n",
        "\n",
        "    # number of filters array\n",
        "    self.nr_filters_array = np.int32(np.minimum(np.ones(depth) * nr_filters * 2 ** np.arange(depth), max_nr_filters))\n",
        "    \n",
        "    # reset seeds\n",
        "    set_seed(0)\n",
        "    seed(0)\n",
        "\n",
        "    # input\n",
        "    se_input = Input(shape=input_shape)\n",
        "    de_input = Input(shape=input_shape)\n",
        "\n",
        "    # output\n",
        "    output = self.discriminator_path([se_input, de_input], sobel_gradient)\n",
        "\n",
        "    # build and compile\n",
        "    self.model = Model(inputs=[se_input, de_input], outputs=output, name=f\"dis_sg{int(sobel_gradient)}\")\n",
        "    self.optimizer = Adam(learning_rate=2e-6, beta_1=0.9)\n",
        "\n",
        "  def discriminator_path(self, inputs, sobel_gradient):\n",
        "    out = Concatenate(axis=3)(inputs)\n",
        "    if sobel_gradient: \n",
        "      out = SobelGradient()(out)\n",
        "    for i, nr_filters in enumerate(self.nr_filters_array):\n",
        "      out = conv_block(out, nr_filters, 4, strides=2, use_bias=True) # encoder block\n",
        "\n",
        "    # final dense layer\n",
        "    out = Dense(1)(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQgdIA0V8Vu9"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuj0ejU_8V0-"
      },
      "source": [
        "class Gan:\n",
        "  def __init__(self, data_feeder, gen_nr_add_scales=0, dis_sobel_gradient=False):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "     data_feeder          DataFeeder object\n",
        "     gen_nr_add_scales    number of multi-scale blocks for the generator\n",
        "     dis_sobel_gradient   Sobel gradient layer on discriminator inputs\n",
        "\n",
        "    outputs:\n",
        "     GAN model based on input settings\n",
        "    \"\"\"\n",
        "\n",
        "    self.data_feeder = data_feeder\n",
        "    input_shape = np.load(self.data_feeder.single_energy_dirs[0]).shape\n",
        "    output_shape = np.load(self.data_feeder.dual_energy_dirs[0]).shape\n",
        "    self.generator = UNet((input_shape, output_shape), nr_add_scales=gen_nr_add_scales)\n",
        "    self.discriminator = Discriminator(output_shape, sobel_gradient=dis_sobel_gradient)\n",
        "    self.name = f\"gan({self.generator.model.name}+{self.discriminator.model.name})\"\n",
        "    \n",
        "    # training initialization\n",
        "    self.loss_object = BinaryCrossentropy(from_logits=True)\n",
        "    self.gen_lambda = Variable(200.0)\n",
        "\n",
        "  def train(self, nr_epochs=100):\n",
        "    # show training data examples\n",
        "    self.data_feeder.show_data_examples()\n",
        "\n",
        "    # initalize/initial calculations\n",
        "    progress_marker = int(max([self.data_feeder.nr_batches / 30, 1]))\n",
        "    self.losses = []\n",
        "\n",
        "    # train\n",
        "    train_start_time = get_start_time()\n",
        "    print(f\"training for {nr_epochs} epochs with {self.data_feeder.nr_batches} batches per epoch\")\n",
        "    for epoch_nr in range(1, nr_epochs + 1):      \n",
        "      print(f\"epoch {epoch_nr} \", end=\"\")\n",
        "      batch_start_time = get_start_time()\n",
        "      for batch_nr in range(self.data_feeder.nr_batches):\n",
        "        # train with gradient tape step and save losses\n",
        "        self.train_step_tape()\n",
        "\n",
        "        # update progress bar based on number of batches\n",
        "        if batch_nr % progress_marker == 0: print(\"=\", end=\"\")\n",
        "\n",
        "      # print results of epoch\n",
        "      print(f\" - {self.losses[-1][0]:.3f} {self.losses[-1][1]:.3f} {self.losses[-1][2]:.3f} | {self.losses[-1][3]:.4f} {self.losses[-1][4]:.3f} {self.losses[-1][5]:.2e} - {get_formatted_elapsed_time(batch_start_time)}\")\n",
        "\n",
        "      # visualize generator results every 10 epochs, with more visualization every 50 and at the end \n",
        "      visualize_training(self.data_feeder, self.generator.model, epoch_nr if epoch_nr != nr_epochs else 0)\n",
        "\n",
        "    # loss lists to numpy arrays\n",
        "    self.losses = np.array(self.losses).T\n",
        "    print(f\"total training time: {get_formatted_elapsed_time(train_start_time)}\")\n",
        "\n",
        "  def train_step_tape(self):\n",
        "    # get real images\n",
        "    se, de_real = self.data_feeder.load_augmented_batch()\n",
        "\n",
        "    # train \n",
        "    losses = self.gradient_tape(se, de_real)\n",
        "\n",
        "    # save losses\n",
        "    self.losses.append(np.array([loss.numpy() for loss in losses]))\n",
        "\n",
        "  def get_gen_loss(self, dis_fake_output, de_fake, de_real):\n",
        "    # adversarial loss\n",
        "    adv_loss = self.loss_object(tf.ones_like(dis_fake_output), dis_fake_output)\n",
        "\n",
        "    # L1 loss/mean absolute error\n",
        "    l1_loss = tf.reduce_mean(tf.abs(de_fake - de_real))\n",
        "\n",
        "    # adversarial + lambda * L1\n",
        "    total_gen_loss = adv_loss + self.gen_lambda * l1_loss\n",
        "\n",
        "    return total_gen_loss, adv_loss, l1_loss\n",
        "  \n",
        "  def get_dis_loss(self, dis_real_output, dis_fake_output):\n",
        "    # real and fake loss\n",
        "    real_loss = self.loss_object(tf.ones_like(dis_real_output), dis_real_output)\n",
        "    fake_loss = self.loss_object(tf.zeros_like(dis_fake_output), dis_fake_output)\n",
        "\n",
        "    # real + fake loss\n",
        "    total_dis_loss = real_loss + fake_loss\n",
        "\n",
        "    return total_dis_loss, real_loss, fake_loss\n",
        "        \n",
        "  @tf.function # tensorflow function for speed\n",
        "  def gradient_tape(self, se, de_real):\n",
        "    # use gradient tape\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
        "      # get fake images\n",
        "      de_fake = self.generator.model(se, training=True)\n",
        "\n",
        "      # # discrminator output on real and fake images\n",
        "      dis_real_output = self.discriminator.model([se, de_real], training=True)\n",
        "      dis_fake_output = self.discriminator.model([se, de_fake], training=True)\n",
        "\n",
        "      # get losses\n",
        "      gen_tot_loss, gen_adv_loss, gen_l1_loss = self.get_gen_loss(dis_fake_output, de_fake, de_real)\n",
        "      dis_tot_loss, dis_real_loss, dis_fake_loss = self.get_dis_loss(dis_real_output, dis_fake_output)\n",
        "\n",
        "    # get gradients\n",
        "    gen_gradients = gen_tape.gradient(gen_tot_loss, self.generator.model.trainable_variables)\n",
        "    dis_gradients = dis_tape.gradient(dis_tot_loss, self.discriminator.model.trainable_variables)\n",
        "\n",
        "    # apply gradients\n",
        "    self.generator.optimizer.apply_gradients(zip(gen_gradients, self.generator.model.trainable_variables))\n",
        "    self.discriminator.optimizer.apply_gradients(zip(dis_gradients, self.discriminator.model.trainable_variables))\n",
        "\n",
        "    return dis_tot_loss, dis_real_loss, dis_fake_loss, gen_tot_loss, gen_adv_loss, gen_l1_loss\n",
        "    \n",
        "  def save(self, save_dir, name_suffix = \"\"):\n",
        "    # save model\n",
        "    model_sir = f\"{save_dir}/{self.name}{name_suffix}\"\n",
        "    save_model(self.generator.model, model_sir)\n",
        "\n",
        "    # save losses\n",
        "    np.save(f\"{model_sir}/model_loss.npy\", self.losses)\n",
        "\n",
        "  def plot_losses(self):\n",
        "    # plot all training losses\n",
        "    titles = [\"total discriminator loss\", \"discriminator real loss\", \"discriminator fake loss\", \"total generator loss\", \"generator adverserial loss\", \"generator L1/MAE loss\"]\n",
        "    fix, axs = plt.subplots(2, 3, figsize=(30, 20))\n",
        "    for i in range(6):\n",
        "      axs[i // 3, i % 3].plot(self.losses[i]); axs[i // 3, i % 3].set_title(titles[i], fontsize=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJI82U5Fuq6Q"
      },
      "source": [
        "# visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQMYd5NIivak"
      },
      "source": [
        "def visualize(plot_save_dir):\n",
        "  # define example input and output shapes\n",
        "  input_shape = (512, 512, 1) # (256, 256, 4)\n",
        "  output_shape = (512, 512, 1) # (256, 256, 4)\n",
        "\n",
        "  # get UNet generators and PatchGAN discriminators with and without mutli-scale or sobel gradient inputs\n",
        "  unet_default = UNet((input_shape, output_shape))\n",
        "  unet_multi_scale = UNet((input_shape, output_shape), nr_add_scales=3)\n",
        "  discriminator_default = Discriminator(input_shape)\n",
        "  discriminator_sobel_filter =  Discriminator(input_shape, sobel_gradient=True)\n",
        "\n",
        "  # print model summaries and save model plots\n",
        "  models = [unet_default, unet_multi_scale, discriminator_default, discriminator_sobel_filter]\n",
        "  for model in models:\n",
        "    model.model.summary()\n",
        "    plot_model(model.model, f\"{plot_save_dir}/{model.model.name}_plot.png\", show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfT_t8zjfOXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f85c7a-0d6e-4c5f-89f4-cc49610e8d6f"
      },
      "source": [
        "def main():\n",
        "  visualize(\"models/plots\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main() # only run when used as main notebook, not when imported"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"unet_ms0\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 64) 1088        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 256, 256, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 128 131200      leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 128 512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 128 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 256)  524544      leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 512)  2097664     leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 512)  2048        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 512)  4194816     leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 512)    4194816     leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 4, 4, 512)    4194816     leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 4, 4, 512)    2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 512)    4194816     leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 512)    2359808     leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 1024)   0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 512)  8389120     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 512)  2359808     leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 1024) 0           leaky_re_lu_4[0][0]              \n",
            "                                                                 leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 512)  8389120     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 1024) 0           leaky_re_lu_3[0][0]              \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 256)  4194560     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 256)  1024        conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 256)  590080      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 64, 512)  0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 128 1048704     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 128 512         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 128, 128, 128 147584      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 128 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 128, 256 0           leaky_re_lu_1[0][0]              \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 256, 256, 64) 262208      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 64) 256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 256, 256, 64) 36928       leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 256, 256, 64) 256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 256, 256, 128 0           leaky_re_lu[0][0]                \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 512, 512, 1)  2049        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 512, 512, 1)  0           conv2d_transpose_6[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 49,699,393\n",
            "Trainable params: 49,686,465\n",
            "Non-trainable params: 12,928\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"unet_ms3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 256, 256, 64) 1088        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 256, 256, 64) 256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 128 131200      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 128, 128, 128 512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 256)  524544      leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 512)  2097664     leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 512)  2048        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 512)  4194816     leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 512)    4194816     leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 512)    2048        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 512)    4194816     leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 512)    2048        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 8, 8, 512)    4194816     leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 512)    2048        conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 512)    2359808     leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 512)    2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 8, 1024)   0           leaky_re_lu_24[0][0]             \n",
            "                                                                 leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 16, 16, 512)  8389120     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 512)  2048        conv2d_transpose_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 512)  2048        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 1024) 0           leaky_re_lu_23[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 32, 32, 512)  8389120     concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 512)  2048        conv2d_transpose_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 512)  2359808     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 512)  2048        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 1024) 0           leaky_re_lu_22[0][0]             \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DTran (None, 64, 64, 256)  4194560     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 64, 64, 256)  1024        conv2d_transpose_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 256)  590080      leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 256)  1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 64, 64, 512)  0           leaky_re_lu_21[0][0]             \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DTran (None, 128, 128, 128 1048704     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 128, 128, 128 512         conv2d_transpose_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 128, 128 147584      leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 128, 128, 128 512         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 128, 128, 256 0           leaky_re_lu_20[0][0]             \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 256, 256, 64) 262208      concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 256, 256, 64) 256         conv2d_transpose_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 256, 256, 64) 36928       leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 256, 256, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 256, 256, 1)  577         leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 256, 256, 1)  4           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 128, 128, 1)  1153        leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, 256, 256, 1)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 128, 128, 1)  4           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 1)    2305        leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 256, 256, 1)  10          leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, 128, 128, 1)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 64, 64, 1)    4           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 256, 256, 1)  4           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 128, 128, 1)  10          leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, 64, 64, 1)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, 256, 256, 1)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 128, 128, 1)  4           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 64, 64, 1)    10          leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 256, 256, 128 0           leaky_re_lu_19[0][0]             \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 256, 256, 1)  10          leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, 128, 128, 1)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 64, 64, 1)    4           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 512, 512, 1)  2049        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 512, 512, 1)  0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 128, 128, 1)  10          leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, 64, 64, 1)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 512, 512, 1)  0           conv2d_transpose_13[0][0]        \n",
            "                                                                 up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 512, 512, 1)  0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 64, 1)    10          leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 512, 512, 1)  0           add[0][0]                        \n",
            "                                                                 up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 1)  0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 512, 512, 1)  0           add_1[0][0]                      \n",
            "                                                                 up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 512, 512, 1)  0           add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 49,703,512\n",
            "Trainable params: 49,690,572\n",
            "Non-trainable params: 12,940\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"dis_sg0\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 512, 512, 2)  0           input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 256, 256, 64) 2112        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 256, 256, 64) 256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 128, 128, 128 131200      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 128, 128, 128 512         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 256)  524544      leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 64, 64, 256)  1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 512)  2097664     leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 512)  2048        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32, 32, 1)    513         leaky_re_lu_47[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,759,873\n",
            "Trainable params: 2,757,953\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"dis_sg1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 512, 512, 2)  0           input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sobel_gradient (SobelGradient)  (None, 512, 512, 6)  0           concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 256, 256, 64) 6208        sobel_gradient[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 256, 256, 64) 256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, 256, 256, 64) 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 128, 128, 128 131200      leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 128, 128, 128 512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, 128, 128, 128 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 256)  524544      leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 64, 64, 256)  1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, 64, 64, 256)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 512)  2097664     leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 512)  2048        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, 32, 32, 512)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32, 32, 1)    513         leaky_re_lu_51[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,763,969\n",
            "Trainable params: 2,762,049\n",
            "Non-trainable params: 1,920\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}